{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('car.n.01'), Synset('car.n.02'), Synset('car.n.03'), Synset('car.n.04'), Synset('cable_car.n.01')]\n"
     ]
    }
   ],
   "source": [
    "car_synsets = wn.synsets('car')\n",
    "print(car_synsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemmas [Lemma('car.n.01.car'), Lemma('car.n.01.auto'), Lemma('car.n.01.automobile'), Lemma('car.n.01.machine'), Lemma('car.n.01.motorcar')]\n",
      "definitions a motor vehicle with four wheels; usually propelled by an internal combustion engine\n",
      "hypernyms [Synset('motor_vehicle.n.01')]\n",
      "hyponyms [Synset('ambulance.n.01'), Synset('beach_wagon.n.01'), Synset('bus.n.04'), Synset('cab.n.03'), Synset('compact.n.03'), Synset('convertible.n.01'), Synset('coupe.n.01'), Synset('cruiser.n.01'), Synset('electric.n.01'), Synset('gas_guzzler.n.01'), Synset('hardtop.n.01'), Synset('hatchback.n.01'), Synset('horseless_carriage.n.01'), Synset('hot_rod.n.01'), Synset('jeep.n.01'), Synset('limousine.n.01'), Synset('loaner.n.02'), Synset('minicar.n.01'), Synset('minivan.n.01'), Synset('model_t.n.01'), Synset('pace_car.n.01'), Synset('racer.n.02'), Synset('roadster.n.01'), Synset('sedan.n.01'), Synset('sport_utility.n.01'), Synset('sports_car.n.01'), Synset('stanley_steamer.n.01'), Synset('stock_car.n.01'), Synset('subcompact.n.01'), Synset('touring_car.n.01'), Synset('used-car.n.01')]\n",
      "---------------------------------------- \n",
      "\n",
      "\n",
      "lemmas [Lemma('car.n.02.car'), Lemma('car.n.02.railcar'), Lemma('car.n.02.railway_car'), Lemma('car.n.02.railroad_car')]\n",
      "definitions a wheeled vehicle adapted to the rails of railroad\n",
      "hypernyms [Synset('wheeled_vehicle.n.01')]\n",
      "hyponyms [Synset('baggage_car.n.01'), Synset('cabin_car.n.01'), Synset('club_car.n.01'), Synset('freight_car.n.01'), Synset('guard's_van.n.01'), Synset('handcar.n.01'), Synset('mail_car.n.01'), Synset('passenger_car.n.01'), Synset('slip_coach.n.01'), Synset('tender.n.04'), Synset('van.n.03')]\n",
      "---------------------------------------- \n",
      "\n",
      "\n",
      "lemmas [Lemma('car.n.03.car'), Lemma('car.n.03.gondola')]\n",
      "definitions the compartment that is suspended from an airship and that carries personnel and the cargo and the power plant\n",
      "hypernyms [Synset('compartment.n.02')]\n",
      "hyponyms []\n",
      "---------------------------------------- \n",
      "\n",
      "\n",
      "lemmas [Lemma('car.n.04.car'), Lemma('car.n.04.elevator_car')]\n",
      "definitions where passengers ride up and down\n",
      "hypernyms [Synset('compartment.n.02')]\n",
      "hyponyms []\n",
      "---------------------------------------- \n",
      "\n",
      "\n",
      "lemmas [Lemma('cable_car.n.01.cable_car'), Lemma('cable_car.n.01.car')]\n",
      "definitions a conveyance for passengers or freight on a cable railway\n",
      "hypernyms [Synset('compartment.n.02')]\n",
      "hyponyms []\n",
      "---------------------------------------- \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# most common opperations in wordnet\n",
    "for car in car_synsets:\n",
    "    print('lemmas', car.lemmas())\n",
    "    print('definitions', car.definition())\n",
    "    print('hypernyms', car.hypernyms())\n",
    "    print('hyponyms', car.hyponyms())\n",
    "    print('-'*40, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('battle.n.01'), Synset('fight.n.02'), Synset('competitiveness.n.01'), Synset('fight.n.04'), Synset('fight.n.05'), Synset('contend.v.06'), Synset('fight.v.02'), Synset('fight.v.03'), Synset('crusade.v.01')]\n",
      "[Synset('contend.v.06'), Synset('fight.v.02'), Synset('fight.v.03'), Synset('crusade.v.01')]\n",
      "[Synset('battle.n.01'), Synset('fight.n.02'), Synset('competitiveness.n.01'), Synset('fight.n.04'), Synset('fight.n.05')]\n",
      "n\n"
     ]
    }
   ],
   "source": [
    "# Synsets have an associated part-of-speech \n",
    "fight_all = wn.synsets('fight')\n",
    "print(fight_all)\n",
    "\n",
    "fight_verb = wn.synsets('fight', 'v')\n",
    "print(fight_verb)\n",
    " \n",
    "fight_noun = wn.synsets('fight', 'n')\n",
    "print(fight_noun)\n",
    " \n",
    "print(fight_noun[0].pos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('walk.v.01')\n"
     ]
    }
   ],
   "source": [
    "#query for a very specific synset\n",
    "walk = wn.synset('walk.v.01')\n",
    "print(walk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "0.14285714285714285\n"
     ]
    }
   ],
   "source": [
    "#compute synsets similarity\n",
    "walk = wn.synset('walk.v.01')\n",
    "run = wn.synset('run.v.01')\n",
    "stand = wn.synset('stand.v.01')\n",
    " \n",
    "print (run.path_similarity(walk))\n",
    "print (run.path_similarity(stand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lemma('talk.v.01.talk'), Lemma('talk.v.01.speak')]\n",
      "[108, 53]\n"
     ]
    }
   ],
   "source": [
    "talk = wn.synset('talk.v.01')\n",
    "print (talk.lemmas())\n",
    "\n",
    "# Lemmas in the synset are sorted by count. The most common lemmas are first\n",
    "print([lemma.count() for lemma in talk.lemmas()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('able.a.01')\n",
      "[Lemma('able.a.01.able')]\n",
      "[Lemma('unable.a.01.unable')]\n"
     ]
    }
   ],
   "source": [
    "#query antonym\n",
    "able = wn.synset('able.a.01')\n",
    "print (able)\n",
    "\n",
    "print (able.lemmas())\n",
    "\n",
    "print(able.lemmas()[0].antonyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lemma('ability.n.01.ability'), Lemma('ability.n.02.ability')]\n"
     ]
    }
   ],
   "source": [
    "#find derivationally related forms for a lemma\n",
    "print (able.lemmas()[0].derivationally_related_forms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n",
      "good\n",
      "ox\n",
      "goose\n"
     ]
    }
   ],
   "source": [
    "#Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    " \n",
    "wnl = WordNetLemmatizer()\n",
    "print (wnl.lemmatize('running', wn.VERB))   # run\n",
    " \n",
    "# A few more examples\n",
    "print(wnl.lemmatize('better', wn.ADJ))          # good\n",
    "print(wnl.lemmatize('oxen', wn.NOUN))        # ox\n",
    "print(wnl.lemmatize('geese', wn.NOUN))      # goose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute sentence similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('cat.n.01'), Synset('guy.n.01'), Synset('cat.n.03'), Synset('kat.n.01'), Synset('cat-o'-nine-tails.n.01'), Synset('caterpillar.n.02'), Synset('big_cat.n.01'), Synset('computerized_tomography.n.01')]\n",
      "[Synset('dog.n.01'), Synset('frump.n.01'), Synset('dog.n.03'), Synset('cad.n.01'), Synset('frank.n.02'), Synset('pawl.n.01'), Synset('andiron.n.01')]\n",
      "[Synset('feline.n.01')]\n",
      "[Synset('mammal.n.01')]\n"
     ]
    }
   ],
   "source": [
    "#Properties of a similarity measure\n",
    "from nltk.corpus import wordnet as wn\n",
    " \n",
    "print (wn.synsets('cat', 'n'))\n",
    "\n",
    "print (wn.synsets('dog', 'n'))\n",
    "\n",
    "print (wn.synsets('feline', 'n'))\n",
    "\n",
    "print (wn.synsets('mammal', 'n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "cat = wn.synsets('cat', 'n')[0]     # Get the most common synset\n",
    "print (cat.lemmas()[0].count())       # Get the first lemma => 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity(Synset('cat.n.01'), Synset('dog.n.01')) = 0.8571428571428571\n",
      "Similarity(Synset('cat.n.01'), Synset('feline.n.01')) = 0.9629629629629629\n",
      "Similarity(Synset('cat.n.01'), Synset('mammal.n.01')) = 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "dog = wn.synsets('dog', 'n')[0]           # Get the most common synset\n",
    "feline = wn.synsets('feline', 'n')[0]     # Get the most common synset\n",
    "mammal = wn.synsets('mammal', 'n')[0]     # Get the most common synset\n",
    " \n",
    "for synset in [dog, feline, mammal]:\n",
    "    print (\"Similarity(%s, %s) = %s\" % (cat, synset, cat.wup_similarity(synset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity(\"Cats are beautiful animals.\", \"Dogs are awesome.\") = 0.5111111111111111\n",
      "Similarity(\"Dogs are awesome.\", \"Cats are beautiful animals.\") = 0.6666666666666666\n",
      "Similarity(\"Cats are beautiful animals.\", \"Some gorgeous creatures are felines.\") = 0.8333333333333334\n",
      "Similarity(\"Some gorgeous creatures are felines.\", \"Cats are beautiful animals.\") = 0.8333333333333334\n",
      "Similarity(\"Cats are beautiful animals.\", \"Dolphins are swimming mammals.\") = 0.48333333333333334\n",
      "Similarity(\"Dolphins are swimming mammals.\", \"Cats are beautiful animals.\") = 0.4\n",
      "Similarity(\"Cats are beautiful animals.\", \"Cats are beautiful animals.\") = 1.0\n",
      "Similarity(\"Cats are beautiful animals.\", \"Cats are beautiful animals.\") = 1.0\n"
     ]
    }
   ],
   "source": [
    "#Implementing the similarity measure\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import wordnet as wn\n",
    " \n",
    "def penn_to_wn(tag):\n",
    "    \"\"\" Convert between a Penn Treebank tag to a simplified Wordnet tag \"\"\"\n",
    "    if tag.startswith('N'):\n",
    "        return 'n'\n",
    " \n",
    "    if tag.startswith('V'):\n",
    "        return 'v'\n",
    " \n",
    "    if tag.startswith('J'):\n",
    "        return 'a'\n",
    " \n",
    "    if tag.startswith('R'):\n",
    "        return 'r'\n",
    " \n",
    "    return None\n",
    " \n",
    "def tagged_to_synset(word, tag):\n",
    "    wn_tag = penn_to_wn(tag)\n",
    "    if wn_tag is None:\n",
    "        return None\n",
    " \n",
    "    try:\n",
    "        return wn.synsets(word, wn_tag)[0]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def sentence_similarity(sentence1, sentence2):\n",
    "    \"\"\" compute the sentence similarity using Wordnet \"\"\"\n",
    "    # Tokenize and tag\n",
    "    sentence1 = pos_tag(word_tokenize(sentence1))\n",
    "    sentence2 = pos_tag(word_tokenize(sentence2))\n",
    " \n",
    "    # Get the synsets for the tagged words\n",
    "    synsets1 = [tagged_to_synset(*tagged_word) for tagged_word in sentence1]\n",
    "    synsets2 = [tagged_to_synset(*tagged_word) for tagged_word in sentence2]\n",
    " \n",
    "    # Filter out the Nones\n",
    "    synsets1 = [ss for ss in synsets1 if ss]\n",
    "    synsets2 = [ss for ss in synsets2 if ss]\n",
    "\n",
    "    score, count = 0.0, 0\n",
    " \n",
    "    # For each word in the first sentence\n",
    "    for synset in synsets1:\n",
    "        # Get the similarity value of the most similar word in the other sentence\n",
    "        #print([s for s in [synset.path_similarity(ss) for ss in synsets2] if s])\n",
    "        best_score  = [s for s in [synset.path_similarity(ss) for ss in synsets2] if s]\n",
    "        if len(best_score)>=1:\n",
    "            best_score  = max(best_score)\n",
    "        else:\n",
    "            best_score = None\n",
    "\n",
    "        # Check that the similarity could have been computed\n",
    "        if best_score is not None:\n",
    "            score += best_score\n",
    "            count += 1\n",
    " \n",
    "    # Average the values\n",
    "    score /= count\n",
    "    return score\n",
    " \n",
    "sentences = [\n",
    "    \"Dogs are awesome.\",\n",
    "    \"Some gorgeous creatures are felines.\",\n",
    "    \"Dolphins are swimming mammals.\",\n",
    "    \"Cats are beautiful animals.\",\n",
    "]\n",
    " \n",
    "focus_sentence = \"Cats are beautiful animals.\"\n",
    " \n",
    "for sentence in sentences:\n",
    "    print (\"Similarity(\\\"%s\\\", \\\"%s\\\") = %s\" % (focus_sentence, sentence, sentence_similarity(focus_sentence, sentence)))\n",
    "    print (\"Similarity(\\\"%s\\\", \\\"%s\\\") = %s\" % (sentence, focus_sentence, sentence_similarity(sentence, focus_sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SymmetricSimilarity(\"Cats are beautiful animals.\", \"Dogs are awesome.\") = 0.5888888888888888\n",
      "SymmetricSimilarity(\"Dogs are awesome.\", \"Cats are beautiful animals.\") = 0.5888888888888888\n",
      "SymmetricSimilarity(\"Cats are beautiful animals.\", \"Some gorgeous creatures are felines.\") = 0.8333333333333334\n",
      "SymmetricSimilarity(\"Some gorgeous creatures are felines.\", \"Cats are beautiful animals.\") = 0.8333333333333334\n",
      "SymmetricSimilarity(\"Cats are beautiful animals.\", \"Dolphins are swimming mammals.\") = 0.44166666666666665\n",
      "SymmetricSimilarity(\"Dolphins are swimming mammals.\", \"Cats are beautiful animals.\") = 0.44166666666666665\n",
      "SymmetricSimilarity(\"Cats are beautiful animals.\", \"Cats are beautiful animals.\") = 1.0\n",
      "SymmetricSimilarity(\"Cats are beautiful animals.\", \"Cats are beautiful animals.\") = 1.0\n"
     ]
    }
   ],
   "source": [
    "#Building a symmetric similarity function\n",
    "def symmetric_sentence_similarity(sentence1, sentence2):\n",
    "    \"\"\" compute the symmetric sentence similarity using Wordnet \"\"\"\n",
    "    return (sentence_similarity(sentence1, sentence2) + sentence_similarity(sentence2, sentence1)) / 2 \n",
    " \n",
    "for sentence in sentences:\n",
    "    print (\"SymmetricSimilarity(\\\"%s\\\", \\\"%s\\\") = %s\" % (\n",
    "        focus_sentence, sentence, symmetric_sentence_similarity(focus_sentence, sentence)))\n",
    "    print (\"SymmetricSimilarity(\\\"%s\\\", \\\"%s\\\") = %s\" % (\n",
    "        sentence, focus_sentence, symmetric_sentence_similarity(sentence, focus_sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
